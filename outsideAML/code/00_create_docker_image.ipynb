{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/datadrive01/prj/transfer_learning/outsideAML/code\n",
      "total 284\n",
      "-rw-rw-r-- 1 loginVM_001 loginVM_001 265312 Sep 25 03:31 00_create_docker_image.html\n",
      "-rw-rw-r-- 1 loginVM_001 loginVM_001  14236 Sep 25 03:32 00_create_docker_image.ipynb\n",
      "-rw-rw-r-- 1 loginVM_001 loginVM_001   6602 Sep 25 01:27 edit_python_files.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -l ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "# This cell is tagged `parameters`\n",
    "# Please modify the values below as you see fit\n",
    "\n",
    "# Your docker login and image repository name\n",
    "docker_login = 'georgedockeraccount'\n",
    "image_tag = \"/transfer_learning_analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwxrwx 3 root root 4096 Sep 25 03:32 code\r\n",
      "drwxrwxrwx 2 root root 4096 Sep 25 01:49 docker\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./../docker/dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./../docker/dockerfile\n",
    "\n",
    "FROM debian:9.5\n",
    "\n",
    "MAINTAINER George Iordanescu <ghiordan@microsoft.com>\n",
    "\n",
    "# Install system packages\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "      apt-utils \\\n",
    "      apt-transport-https \\ \n",
    "      ca-certificates \\\n",
    "      curl \\\n",
    "      bzip2 \\\n",
    "      g++ \\\n",
    "      git \\\n",
    "      graphviz \\\n",
    "      wget \\\n",
    "      ssh \\\n",
    "      gnupg \\\n",
    "      gnupg2 \\\n",
    "      rsync && \\\n",
    "    rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# Install conda\n",
    "ENV CONDA_DIR /opt/conda\n",
    "ENV PATH $CONDA_DIR/bin:$PATH\n",
    "\n",
    "RUN wget --quiet --no-check-certificate https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh && \\\n",
    "    echo \"c59b3dd3cad550ac7596e0d599b91e75d88826db132e4146030ef471bb434e9a *Miniconda3-4.2.12-Linux-x86_64.sh\" | sha256sum -c - && \\\n",
    "    /bin/bash /Miniconda3-4.2.12-Linux-x86_64.sh -f -b -p $CONDA_DIR && \\\n",
    "    rm Miniconda3-4.2.12-Linux-x86_64.sh && \\\n",
    "    echo export PATH=$CONDA_DIR/bin:'$PATH' > /etc/profile.d/conda.sh\n",
    "        \n",
    "#https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux\n",
    "# https://docs.microsoft.com/en-us/dotnet/core/linux-prerequisites?tabs=netcore2x\n",
    "#https://www.microsoft.com/net/download/linux-package-manager/debian9/runtime-2.1.2\n",
    "RUN wget --no-check-certificate -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > microsoft.asc.gpg && \\\n",
    "    mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/ && \\\n",
    "    wget -q https://packages.microsoft.com/config/debian/9/prod.list && \\\n",
    "    mv prod.list /etc/apt/sources.list.d/microsoft-prod.list && \\\n",
    "    chown root:root /etc/apt/trusted.gpg.d/microsoft.asc.gpg && \\\n",
    "    chown root:root /etc/apt/sources.list.d/microsoft-prod.list  && \\\n",
    "    apt-get update && \\\n",
    "    apt-get install -y --no-install-recommends aspnetcore-runtime-2.1 && \\\n",
    "    mkdir /tmp/azcopy && \\\n",
    "    wget -O /tmp/azcopy/azcopy.tar.gz https://aka.ms/downloadazcopyprlinux &&  \\\n",
    "    tar -xf /tmp/azcopy/azcopy.tar.gz -C /tmp/azcopy &&  \\\n",
    "    /tmp/azcopy/install.sh && \\\n",
    "    rm -rf /tmp/azcopy\n",
    "\n",
    "# Install Python packages and keras\n",
    "ENV NB_USER tlvisuser\n",
    "ENV NB_UID 1000\n",
    "\n",
    "RUN useradd -m -s /bin/bash -N -u $NB_UID $NB_USER && \\\n",
    "    chown $NB_USER $CONDA_DIR -R && \\\n",
    "    mkdir -p /src && \\\n",
    "    chown $NB_USER /src\n",
    "\n",
    "USER $NB_USER\n",
    "\n",
    "ARG python_version=3.6\n",
    "\n",
    "# tensorflow-gpu 1.10.1 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.2 which is incompatible.\n",
    "RUN conda install -y python=${python_version} && \\\n",
    "    pip install --upgrade pip && \\\n",
    "    pip install \\\n",
    "      sklearn_pandas \\\n",
    "      scikit-image \\\n",
    "      tensorflow \\\n",
    "      tensorflow-tensorboard \\\n",
    "      numpy==1.14.5 && \\\n",
    "    conda install \\\n",
    "      glob2 \\\n",
    "      h5py \\\n",
    "      matplotlib \\\n",
    "      mkl \\\n",
    "      nose \\\n",
    "      notebook \\\n",
    "      opencv \\\n",
    "      pandas \\\n",
    "      requests \\\n",
    "      scikit-learn \\\n",
    "      scipy \\\n",
    "      six \\\n",
    "      tqdm && \\\n",
    "    conda install -c conda-forge imageio && \\\n",
    "    git clone git://github.com/keras-team/keras.git /src && pip install -e /src[tests] && \\\n",
    "    pip install git+git://github.com/keras-team/keras.git && \\\n",
    "    pip install git+https://www.github.com/keras-team/keras-contrib.git && \\\n",
    "    conda clean -yt     \n",
    "\n",
    "ENV PYTHONPATH='/src/:$PYTHONPATH'\n",
    "\n",
    "WORKDIR /src\n",
    "\n",
    "EXPOSE 8888\n",
    "\n",
    "# CMD jupyter notebook --port=8888 --ip=0.0.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'georgedockeraccount/transfer_learning_analysis:1.0.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'./../docker/dockerfile'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%dotenv\n",
    "docker_image_name = os.getenv('docker_login') + os.getenv('image_tag') + ':1.0.0'\n",
    "docker_file_location = os.path.join(*(['.', '..','docker', 'dockerfile']))\n",
    "working_path = '.'\n",
    "\n",
    "docker_image_name\n",
    "docker_file_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker build -t georgedockeraccount/transfer_learning_analysis:1.0.0 -f ./../docker/dockerfile .\n",
      "Sending build context to Docker daemon  309.3kB\n",
      "Step 1/16 : FROM debian:9.5\n",
      " ---> f2aae6ff5d89\n",
      "Step 2/16 : MAINTAINER George Iordanescu <ghiordan@microsoft.com>\n",
      " ---> Using cache\n",
      " ---> ac222101e003\n",
      "Step 3/16 : RUN apt-get update && apt-get install -y --no-install-recommends       apt-utils       apt-transport-https       ca-certificates       curl       bzip2       g++       git       graphviz       wget       ssh       gnupg       gnupg2       rsync &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 4a92d6615c5d\n",
      "Step 4/16 : ENV CONDA_DIR /opt/conda\n",
      " ---> Using cache\n",
      " ---> d7b3a1ff7b4f\n",
      "Step 5/16 : ENV PATH $CONDA_DIR/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> bc5384a3eb21\n",
      "Step 6/16 : RUN wget --quiet --no-check-certificate https://repo.continuum.io/miniconda/Miniconda3-4.2.12-Linux-x86_64.sh &&     echo \"c59b3dd3cad550ac7596e0d599b91e75d88826db132e4146030ef471bb434e9a *Miniconda3-4.2.12-Linux-x86_64.sh\" | sha256sum -c - &&     /bin/bash /Miniconda3-4.2.12-Linux-x86_64.sh -f -b -p $CONDA_DIR &&     rm Miniconda3-4.2.12-Linux-x86_64.sh &&     echo export PATH=$CONDA_DIR/bin:'$PATH' > /etc/profile.d/conda.sh\n",
      " ---> Using cache\n",
      " ---> d747884c2999\n",
      "Step 7/16 : RUN wget --no-check-certificate -qO- https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > microsoft.asc.gpg &&     mv microsoft.asc.gpg /etc/apt/trusted.gpg.d/ &&     wget -q https://packages.microsoft.com/config/debian/9/prod.list &&     mv prod.list /etc/apt/sources.list.d/microsoft-prod.list &&     chown root:root /etc/apt/trusted.gpg.d/microsoft.asc.gpg &&     chown root:root /etc/apt/sources.list.d/microsoft-prod.list  &&     apt-get update &&     apt-get install -y --no-install-recommends aspnetcore-runtime-2.1 &&     mkdir /tmp/azcopy &&     wget -O /tmp/azcopy/azcopy.tar.gz https://aka.ms/downloadazcopyprlinux &&      tar -xf /tmp/azcopy/azcopy.tar.gz -C /tmp/azcopy &&      /tmp/azcopy/install.sh &&     rm -rf /tmp/azcopy\n",
      " ---> Using cache\n",
      " ---> 49b8ca6ecd6f\n",
      "Step 8/16 : ENV NB_USER tlvisuser\n",
      " ---> Using cache\n",
      " ---> 86fea40eefa4\n",
      "Step 9/16 : ENV NB_UID 1000\n",
      " ---> Using cache\n",
      " ---> 90830fe486dc\n",
      "Step 10/16 : RUN useradd -m -s /bin/bash -N -u $NB_UID $NB_USER &&     chown $NB_USER $CONDA_DIR -R &&     mkdir -p /src &&     chown $NB_USER /src\n",
      " ---> Using cache\n",
      " ---> 85b85110db47\n",
      "Step 11/16 : USER $NB_USER\n",
      " ---> Using cache\n",
      " ---> b4f06d40df5e\n",
      "Step 12/16 : ARG python_version=3.6\n",
      " ---> Using cache\n",
      " ---> 5df0e39874ec\n",
      "Step 13/16 : RUN conda install -y python=${python_version} &&     pip install --upgrade pip &&     pip install       sklearn_pandas       scikit-image       tensorflow       tensorflow-tensorboard       numpy==1.14.5 &&     conda install       glob2       h5py       matplotlib       mkl       nose       notebook       opencv       pandas       requests       scikit-learn       scipy       six       tqdm &&     conda install -c conda-forge imageio &&     git clone git://github.com/keras-team/keras.git /src && pip install -e /src[tests] &&     pip install git+git://github.com/keras-team/keras.git &&     pip install git+https://www.github.com/keras-team/keras-contrib.git &&     conda clean -yt\n",
      " ---> Using cache\n",
      " ---> d6b6fe8ffb7f\n",
      "Step 14/16 : ENV PYTHONPATH='/src/:$PYTHONPATH'\n",
      " ---> Using cache\n",
      " ---> 6aa2fa31c78b\n",
      "Step 15/16 : WORKDIR /src\n",
      " ---> Using cache\n",
      " ---> 668e7438259b\n",
      "Step 16/16 : EXPOSE 8888\n",
      " ---> Using cache\n",
      " ---> 8733abb18c08\n",
      "Successfully built 8733abb18c08\n",
      "Successfully tagged georgedockeraccount/transfer_learning_analysis:1.0.0\n"
     ]
    }
   ],
   "source": [
    "!echo docker build -t $docker_image_name -f $docker_file_location $working_path\n",
    "!docker build -t $docker_image_name -f $docker_file_location $working_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/georgedockeraccount/transfer_learning_analysis]\n",
      "\n",
      "\u001b[1Baa3d5292: Preparing \n",
      "\u001b[1B35c623c8: Preparing \n",
      "\u001b[1B379a1fcf: Preparing \n",
      "\u001b[1B8a9c05e5: Preparing \n",
      "\u001b[1Bc39c2b02: Preparing \n",
      "\u001b[1Bf0b6fef8: Layer already exists \u001b[1A\u001b[1K\u001b[K1.0.0: digest: sha256:df1de7fc7dfb1ecc9f2084657a7603144b495eb3cb810bedf0553194bbf069c8 size: 1592\n"
     ]
    }
   ],
   "source": [
    "!docker push $docker_image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run -i -t -p 10003:8888 -v $(pwd):/local_dir:rw georgedockeraccount/transfer_learning_analysis:1.0.0 /bin/bash -c \"/opt/conda/bin/jupyter notebook --notebook-dir=/local_dir --ip=* --port=8888 --no-browser --allow-root\"\r\n"
     ]
    }
   ],
   "source": [
    "!echo docker run -i -t -p 10003:8888 -v '$(pwd)':/local_dir:rw $docker_image_name /bin/bash -c '\"/opt/conda/bin/jupyter notebook --notebook-dir=/local_dir --ip='*' --port=8888 --no-browser --allow-root\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook 00_create_docker_image.ipynb to html\n",
      "[NbConvertApp] Writing 266194 bytes to 00_create_docker_image.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html 00_create_docker_image.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
