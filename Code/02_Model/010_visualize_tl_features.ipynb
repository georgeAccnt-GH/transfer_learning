{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "##### Copyright (C) Microsoft Corporation.  \n",
    "see license file for details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/azureml-share/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AZUREML_NATIVE_SHARE_DIRECTORY mapping to host dir is set by _nativeSharedDirectory_ in .compute file \n",
    "\n",
    "import os\n",
    "try:\n",
    "    amlWBSharedDir = os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']    \n",
    "except:\n",
    "    amlWBSharedDir = ''\n",
    "    print('not using aml services?')\n",
    "    \n",
    "amlWBSharedDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the Azure Machine Learning data collector to log various metrics\n",
    "# from azureml.logging import get_azureml_logger\n",
    "# logger = get_azureml_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Azure Machine Learning history magic to control history collection\n",
    "# History is off by default, options are \"on\", \"off\", or \"show\"\n",
    "# %azureml history on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import utlity functions\n",
    "\n",
    "import sys, os\n",
    "paths_to_append = [os.path.join(os.getcwd(), os.path.join(*(['Code',  'src'])))]\n",
    "def add_path_to_sys_path(path_to_append):\n",
    "    if not (any(path_to_append in paths for paths in sys.path)):\n",
    "        sys.path.append(path_to_append)\n",
    "\n",
    "[add_path_to_sys_path(crt_path) for crt_path in paths_to_append]\n",
    "\n",
    "import trvis_utils, image_featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/azureml-share/data/processed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prj_consts = trvis_utils.trvis_consts()\n",
    "data_base_input_dir=os.path.join(amlWBSharedDir, os.path.join(*(prj_consts.BASE_INPUT_DIR_list)))\n",
    "data_dir = os.path.join(data_base_input_dir, os.path.join(*(['cats_and_dogs', 'train'])))\n",
    "output_dir = os.path.join(data_base_input_dir, os.path.join(*(['processed'])))\n",
    "\n",
    "os.makedirs(output_dir, mode=0o777, exist_ok=True)\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import random\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras_contrib.applications.densenet import DenseNetImageNet121\n",
    "import keras_contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECOMPUTE=True\n",
    "SAMPLE_DATA = False\n",
    "    \n",
    "# densenet layers\n",
    "# name          size    connected_to\n",
    "# dense_2_3_bn  1408    concatenate_311\n",
    "# dense_2_8_bn  2048    concatenate_316 \n",
    "# dense_2_10_bn 2304    concatenate_318  \n",
    "              \n",
    "# model_name_list = [ResNet50, DenseNetImageNet121, DenseNetImageNet121, DenseNetImageNet121, DenseNetImageNet121]\n",
    "# model_layer_list = ['','dense_2_3_bn', 'dense_2_8_bn', 'dense_2_10_bn', '']    \n",
    "model_name_list = [ResNet50]\n",
    "model_layer_list = ['']\n",
    "\n",
    "sample_size = 1000\n",
    "saved_data_file_appendix = ''\n",
    "if SAMPLE_DATA:\n",
    "    saved_data_file_appendix = '_sample'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['dog.6858.jpg', 'dog.1106.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['/azureml-share/data/cats_and_dogs/train/dog.6858.jpg',\n",
       " '/azureml-share/data/cats_and_dogs/train/dog.1106.jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_image_files = os.listdir(data_dir)\n",
    "\n",
    "if SAMPLE_DATA:\n",
    "    training_image_files= random.sample(training_image_files, sample_size)\n",
    "\n",
    "len(training_image_files)\n",
    "training_image_files[:2]\n",
    "image_file_names = list(os.path.join(data_dir, fname) for fname in training_image_files)\n",
    "image_file_names[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels_.npy',\n",
       " 'features_ResNet50tsne.npy',\n",
       " 'labels__sample.npy',\n",
       " 'features_ResNet50.npy',\n",
       " 'features_ResNet50_sample.npy',\n",
       " 'features_ResNet50_sampletsne.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somemodel = DenseNetImageNet121(input_shape=(224, 224, 3),\n",
    "#                                      weights='imagenet',\n",
    "#                                      include_top=False,\n",
    "#                                      pooling=None)\n",
    "# model_summary = somemodel.summary()\n",
    "# model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pretrained_model:\n",
    "    def __init__(self, DL_architecture, intermediate_layer = ''):\n",
    "        self.name = DL_architecture.__name__\n",
    "        pooling_value = 'avg'\n",
    "        if DL_architecture.__name__=='DenseNetImageNet121':\n",
    "            pooling_value = 'None'\n",
    "        crt_model = DL_architecture(input_shape=(224, 224, 3),\n",
    "                                     weights='imagenet',\n",
    "                                     include_top=False,\n",
    "                                     pooling=pooling_value)\n",
    "        if not (intermediate_layer==''):\n",
    "             crt_model = Model(inputs=crt_model.input, outputs=crt_model.get_layer(intermediate_layer).output)\n",
    "        self.model = crt_model\n",
    "\n",
    "def pretrained_models_generator(model_name_list):\n",
    "    \"\"\"Yield successive pretrained models.\"\"\"\n",
    "    for crt_model_name in model_name_list: \n",
    "        yield pretrained_model(crt_model_name)\n",
    "   \n",
    "# crt_pretrained_models = [pretrained_model(ResNet50), pretrained_model(DenseNetImageNet121)]\n",
    "# print(crt_model.name for crt_model in crt_pretrained_models)\n",
    "# models = dict([ (m.name, m.model) for m in crt_pretrained_models ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model ResNet50 layer \n",
      "Computing features\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [05:54,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2048)\n"
     ]
    }
   ],
   "source": [
    "def featurize_images_multiple_models(crt_image_file_names, output_dir, model_name_list, batch_size=64):\n",
    "    for crt_model_name, crt_model_layer in zip(model_name_list, model_layer_list):\n",
    "        print('processing model ' + crt_model_name.__name__+' layer '+crt_model_layer)\n",
    "        features_filename = os.path.join(output_dir, 'features_' +\\\n",
    "                                         crt_model_name.__name__+saved_data_file_appendix+\\\n",
    "                                         crt_model_layer+'.npy')\n",
    "        if os.path.isfile(features_filename) and RECOMPUTE is False:\n",
    "            print(\"Features found!\")\n",
    "        else:\n",
    "            print(\"Computing features\")\n",
    "            crt_model = pretrained_model(crt_model_name, crt_model_layer).model\n",
    "            features = image_featurization.featurize_images(crt_image_file_names, crt_model, batch_size) \n",
    "            print(features.shape)\n",
    "            np.save(features_filename, features)\n",
    "            del crt_model\n",
    "\n",
    "featurize_images_multiple_models(image_file_names, output_dir, model_name_list)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_list = [DenseNetImageNet121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsne processing for model ResNet50\n",
      "Computing tsne features\n",
      "(25000, 2048)\n",
      "(25000, 2048)\n"
     ]
    }
   ],
   "source": [
    "def apply_tsne_to_multiple_features(output_dir, crt_model_name_list):\n",
    "    for crt_model_name, crt_model_layer in zip(model_name_list, model_layer_list):\n",
    "        print('tsne processing for model ' + crt_model_name.__name__)\n",
    "        tsne_features_filename = os.path.join(output_dir, 'features_' + \\\n",
    "                                              crt_model_name.__name__+saved_data_file_appendix+\\\n",
    "                                              crt_model_layer+'tsne.npy')\n",
    "        if os.path.isfile(tsne_features_filename) and RECOMPUTE is False:\n",
    "            print(\"tsne features found!\")\n",
    "        else:\n",
    "            print(\"Computing tsne features\")\n",
    "            original_features = np.load(os.path.join(output_dir, 'features_' + \\\n",
    "                                                     crt_model_name.__name__+saved_data_file_appendix+\\\n",
    "                                                     crt_model_layer+'.npy'))\n",
    "            print(original_features.shape)\n",
    "            original_features = original_features.reshape(original_features.shape[0], -1)\n",
    "            print(original_features.shape)\n",
    "            images_tsne = TSNE(n_components=2, random_state=0).fit_transform(original_features)\n",
    "            print(images_tsne.shape)\n",
    "            np.save(tsne_features_filename, images_tsne)\n",
    "apply_tsne_to_multiple_features(output_dir, model_name_list)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_filename = os.path.join(output_dir, 'labels_' + \\\n",
    "                                              saved_data_file_appendix+\\\n",
    "                                              '.npy')\n",
    "if os.path.isfile(labels_filename) and RECOMPUTE is False:\n",
    "    print('Label file '+labels_filename+' found!')\n",
    "    y = np.load(labels_filename)\n",
    "else:\n",
    "  y = pd.Series(training_image_files).str.contains('cat').astype(int).values\n",
    "  np.save(labels_filename, y)\n",
    "\n",
    "print(y.shape)\n",
    "print(y[y==0].shape)\n",
    "print(y[y==1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_labels = y == 0\n",
    "dog_labels = y == 1\n",
    "def visualize_tsne_features(crt_model_name_list):\n",
    "    for crt_model_name, crt_model_layer in zip(model_name_list, model_layer_list):\n",
    "        tsne_features_filename = os.path.join(output_dir, 'features_' + \\\n",
    "                                              crt_model_name.__name__+saved_data_file_appendix+\\\n",
    "                                              crt_model_layer+'tsne.npy')\n",
    "        tsne_features = np.load(tsne_features_filename)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(x = tsne_features[:,0], y=tsne_features[:,1], marker=\".\", c=y, cmap=plt.cm.get_cmap('bwr'))\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "visualize_tsne_features(model_name_list)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbconvert --to html 010_visualize_tl_features.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghiordtrvisprj01 gpuvmcc",
   "language": "python",
   "name": "ghiordtrvisprj01_gpuvmcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
